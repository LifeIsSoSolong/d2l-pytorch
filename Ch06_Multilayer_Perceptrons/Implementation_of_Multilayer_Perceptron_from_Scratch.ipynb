{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of Multilayer Perceptron from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how multilayer perceptrons (MLPs) work in theory, let’s implement them. First, we import the required\n",
    "packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import d2l\n",
    "from d2l.data import load_data_fashion_mnist\n",
    "from d2l.train import train_ch3\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import  numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare against the results we previously achieved with vanilla softmax regression, we continue to use the Fashion-\n",
    "MNIST image classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that this dataset contains 10 classes and that each image consists of a 28 × 28 = 784 grid of pixel values. Since\n",
    "we’ll be discarding the spatial strucutre (for now), we can just think of this as a classifiation dataset with 784 input features\n",
    "and 10 classes. In particular we will implement our MLP with one hidden layer and 256 hidden units. Note that we can\n",
    "regard both of these choices as hyperparameters that could be set based on performance on validation data. Typically,\n",
    "we’ll choose layer widths as powers of 2 to make everything align nicely in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure we know how everything works, we will use the maximum function to implement ReLU ourselves, instead\n",
    "of invoking nn.ReLU directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.W1 = nn.Parameter(torch.randn(784,256,requires_grad=True)*0.01)\n",
    "        self.b1 = nn.Parameter(torch.zeros(256,requires_grad=True))\n",
    "        self.W2 = nn.Parameter(torch.randn(256,10,requires_grad=True)*0.01)\n",
    "        self.b2 = nn.Parameter(torch.zeros(10,requires_grad=True))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.reshape((-1, 784))\n",
    "        H=self.relu(X@self.W1 + self.b1)   # Here '@' stands for dot product operation\n",
    "        return (H@self.W2 + self.b2)\n",
    "    \n",
    "    def relu(self, s):\n",
    "        a=torch.zeros_like(s)\n",
    "        return torch.max(s, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in softmax regression, we will reshape each 2D image into a flat vector of length num_inputs. Finally, we cam\n",
    "implement our model with just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net=Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better numerical stability and because we already know how to implement softmax regression completely from scratch\n",
    "in Section 3.6, we will use torch’s integrated function for calculating the softmax and cross-entropy loss. Recall that we\n",
    "discussed some of these intricacies in Section 4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for training the MLP are no different than for softmax regression. In the d2l package, we directly call the\n",
    "train_ch3 function. We set the number of epochs to 10 and the learning rate to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0031, train acc 0.699, test acc 0.779\n",
      "epoch 2, loss 0.0019, train acc 0.820, test acc 0.825\n",
      "epoch 3, loss 0.0017, train acc 0.840, test acc 0.844\n",
      "epoch 4, loss 0.0015, train acc 0.856, test acc 0.853\n",
      "epoch 5, loss 0.0014, train acc 0.863, test acc 0.840\n",
      "epoch 6, loss 0.0014, train acc 0.869, test acc 0.848\n",
      "epoch 7, loss 0.0013, train acc 0.876, test acc 0.813\n",
      "epoch 8, loss 0.0013, train acc 0.882, test acc 0.840\n",
      "epoch 9, loss 0.0012, train acc 0.883, test acc 0.858\n",
      "epoch 10, loss 0.0012, train acc 0.887, test acc 0.871\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr = 10, 0.5\n",
    "train_ch3(net, train_iter, test_iter, criterion, num_epochs, batch_size, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well we did, let’s apply the model to some test data. If you’re interested, compare the result to corresponding linear model in Section 3.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e69d5f9f1b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fashion_mnist_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fashion_mnist_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtruelabel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtruelabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_iter' is not defined"
     ]
    }
   ],
   "source": [
    "for X, y in test_iter:\n",
    "    break\n",
    "true_labels = d2l.get_fashion_mnist_labels(y.numpy())\n",
    "pred_labels = d2l.get_fashion_mnist_labels(np.argmax(net(X).data.numpy(), axis=1))\n",
    "titles = [truelabel + '\\n' + predlabel for truelabel, predlabel in zip(true_labels, pred_labels)]\n",
    "d2l.show_fashion_mnist(X[0:9], titles[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a bit better than our previous result, a good sign that we’re on the right path."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that implementing a simple MLP is easy, even when done manually. That said, with a large number of layers,\n",
    "this can get messy (e.g. naming and keeping track of the model parameters, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the value of the hyper-parameter num_hiddens in order to see how this hyperparameter influences your\n",
    "results.\n",
    "2. Try adding a new hidden layer to see how it affects the results.\n",
    "3. How does changing the learning rate change the result.\n",
    "4. What is the best result you can get by optimizing over all the parameters (learning rate, iterations, number of hidden\n",
    "layers, number of hidden units per layer)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014).  JMLR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
